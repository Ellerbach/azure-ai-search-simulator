{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af4bdd2",
   "metadata": {},
   "source": [
    "# Azure AI Search Simulator - Embedding Skill Demo\n",
    "\n",
    "This notebook demonstrates how to use the **Azure OpenAI Embedding Skill** with the Azure AI Search Simulator to generate vector embeddings for semantic search.\n",
    "\n",
    "## What This Notebook Covers\n",
    "\n",
    "1. **Vector Index Creation** - Create an index with vector fields for embeddings\n",
    "2. **Skillset with Embedding Skill** - Configure Azure OpenAI Embedding skill\n",
    "3. **Indexer with Enrichment** - Process documents and generate embeddings\n",
    "4. **Vector Search** - Perform similarity search using embeddings\n",
    "5. **Hybrid Search** - Combine keyword and vector search with RRF fusion\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Start the Azure AI Search Simulator with HTTPS**:\n",
    "   ```bash\n",
    "   cd src/AzureAISearchSimulator.Api\n",
    "   dotnet run --urls \"https://localhost:7250\"\n",
    "   ```\n",
    "\n",
    "2. **Configure Azure OpenAI** in `appsettings.json`:\n",
    "   ```json\n",
    "   {\n",
    "     \"AzureOpenAI\": {\n",
    "       \"Endpoint\": \"https://your-resource.openai.azure.com\",\n",
    "       \"ApiKey\": \"your-api-key\",\n",
    "       \"EmbeddingDeployment\": \"text-embedding-ada-002\"\n",
    "     }\n",
    "   }\n",
    "   ```\n",
    "\n",
    "3. **Sample data files** are located in `../IndexerTestNotebook/data`\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: The Azure SDK requires HTTPS. The simulator must run on `https://localhost:7250`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705977cb",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6ea13a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install azure-search-documents requests pandas numpy\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import urllib3\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Azure AI Search SDK imports\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerSkillset,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    FieldMapping,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    ")\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# For displaying results\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Suppress SSL warnings for local development\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d2677",
   "metadata": {},
   "source": [
    "## 2. Initialize Azure AI Search Clients\n",
    "\n",
    "Configure connection to the local Azure AI Search Simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e06776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Azure AI Search Simulator at https://localhost:7250\n",
      "üìÅ Data path: C:\\Projets\\AzureAISimulator\\samples\\IndexerTestNotebook\\data\n",
      "üìÑ Found 5 JSON metadata files\n",
      "üìÑ Found 5 TXT content files\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Azure AI Search Simulator\n",
    "SEARCH_ENDPOINT = \"https://localhost:7250\"\n",
    "ADMIN_API_KEY = \"admin-key-12345\"\n",
    "\n",
    "# Azure OpenAI Configuration (update with your values)\n",
    "# The simulator will use these when calling Azure OpenAI for embeddings\n",
    "AZURE_OPENAI_ENDPOINT = \"https://your-open-ai-url.cognitiveservices.azure.com\"  # Update this\n",
    "AZURE_OPENAI_DEPLOYMENT = \"text-embedding-3-small\"  # Or your deployment name\n",
    "\n",
    "# ‚ö†Ô∏è IMPORTANT: Set your Azure OpenAI API key here\n",
    "# Get it from: Azure Portal ‚Üí Your Azure OpenAI/AI Services resource ‚Üí Keys and Endpoint\n",
    "# AZURE_OPENAI_API_KEY = \"YOUR-AZURE-OPENAI-API-KEY-HERE\"  # <-- UPDATE THIS!\n",
    "AZURE_OPENAI_API_KEY = \"YOUR-AZURE-OPENAI-API-KEY-HERE\"  # <-- UPDATE THIS!\n",
    "\n",
    "# Resource names for this demo\n",
    "INDEX_NAME = \"embedding-demo-docs\"\n",
    "DATA_SOURCE_NAME = \"embedding-demo-files\"\n",
    "SKILLSET_NAME = \"embedding-skillset\"\n",
    "INDEXER_NAME = \"embedding-indexer\"\n",
    "\n",
    "# Path to sample data (from IndexerTestNotebook)\n",
    "DATA_PATH = Path(\"../IndexerTestNotebook/data\").resolve()\n",
    "\n",
    "# Embedding dimensions (text-embedding-3-small uses 1536)\n",
    "EMBEDDING_DIMENSIONS = 1536\n",
    "\n",
    "# Create credentials\n",
    "admin_credential = AzureKeyCredential(ADMIN_API_KEY)\n",
    "\n",
    "# Configure HTTP transport to skip SSL certificate validation for local development\n",
    "import requests as req_lib\n",
    "from azure.core.pipeline.transport import RequestsTransport\n",
    "\n",
    "session = req_lib.Session()\n",
    "session.verify = False\n",
    "transport = RequestsTransport(session=session, connection_verify=False)\n",
    "\n",
    "# Create clients\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    credential=admin_credential,\n",
    "    transport=transport,\n",
    "    connection_verify=False\n",
    ")\n",
    "\n",
    "indexer_client = SearchIndexerClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    credential=admin_credential,\n",
    "    transport=transport,\n",
    "    connection_verify=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Connected to Azure AI Search Simulator at {SEARCH_ENDPOINT}\")\n",
    "print(f\"üìÅ Data path: {DATA_PATH}\")\n",
    "\n",
    "# List sample data files\n",
    "if DATA_PATH.exists():\n",
    "    json_files = list(DATA_PATH.glob(\"*.json\"))\n",
    "    txt_files = list(DATA_PATH.glob(\"*.txt\"))\n",
    "    print(f\"üìÑ Found {len(json_files)} JSON metadata files\")\n",
    "    print(f\"üìÑ Found {len(txt_files)} TXT content files\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Data path not found. Make sure IndexerTestNotebook/data exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06dfa64",
   "metadata": {},
   "source": [
    "## 3. Review Sample Data\n",
    "\n",
    "Let's look at the sample documents we'll be indexing with embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98a276aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Sample Documents to Index (5 total):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>content_preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc-001</td>\n",
       "      <td>Introduction to Azure AI Search</td>\n",
       "      <td>Azure Documentation Team</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>Azure AI Search is a cloud search service with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc-002</td>\n",
       "      <td>Creating Search Indexes</td>\n",
       "      <td>Search Engineering Team</td>\n",
       "      <td>Tutorial</td>\n",
       "      <td>A search index in Azure AI Search is a persist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc-003</td>\n",
       "      <td>Understanding Indexers and Data Sources</td>\n",
       "      <td>Data Integration Team</td>\n",
       "      <td>Tutorial</td>\n",
       "      <td>Indexers in Azure AI Search automate the inges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc-004</td>\n",
       "      <td>Search Query Syntax Guide</td>\n",
       "      <td>Query Processing Team</td>\n",
       "      <td>Reference</td>\n",
       "      <td>Azure AI Search supports multiple query syntax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc-005</td>\n",
       "      <td>Security and Access Control</td>\n",
       "      <td>Security Team</td>\n",
       "      <td>Security</td>\n",
       "      <td>Azure AI Search provides multiple layers of se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                    title                    author  \\\n",
       "0  doc-001          Introduction to Azure AI Search  Azure Documentation Team   \n",
       "1  doc-002                  Creating Search Indexes   Search Engineering Team   \n",
       "2  doc-003  Understanding Indexers and Data Sources     Data Integration Team   \n",
       "3  doc-004                Search Query Syntax Guide     Query Processing Team   \n",
       "4  doc-005              Security and Access Control             Security Team   \n",
       "\n",
       "        category                                    content_preview  \n",
       "0  Documentation  Azure AI Search is a cloud search service with...  \n",
       "1       Tutorial  A search index in Azure AI Search is a persist...  \n",
       "2       Tutorial  Indexers in Azure AI Search automate the inges...  \n",
       "3      Reference  Azure AI Search supports multiple query syntax...  \n",
       "4       Security  Azure AI Search provides multiple layers of se...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display sample data\n",
    "sample_docs = []\n",
    "\n",
    "for json_file in sorted(DATA_PATH.glob(\"*.json\")):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    # Read associated content file\n",
    "    content_file = DATA_PATH / metadata.get('contentFile', '')\n",
    "    content = \"\"\n",
    "    if content_file.exists():\n",
    "        with open(content_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "    \n",
    "    sample_docs.append({\n",
    "        'id': metadata['id'],\n",
    "        'title': metadata['title'],\n",
    "        'author': metadata['author'],\n",
    "        'category': metadata['category'],\n",
    "        'content': content,\n",
    "        'content_preview': content[:150] + \"...\" if len(content) > 150 else content\n",
    "    })\n",
    "\n",
    "# Display as DataFrame\n",
    "df = pd.DataFrame(sample_docs)\n",
    "print(f\"üìö Sample Documents to Index ({len(sample_docs)} total):\\n\")\n",
    "display(df[['id', 'title', 'author', 'category', 'content_preview']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6dc97",
   "metadata": {},
   "source": [
    "## 4. Create Search Index with Vector Field\n",
    "\n",
    "Define an index schema that includes a vector field for embeddings. We'll use HNSW algorithm for efficient vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1664c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index 'embedding-demo-docs' created/updated successfully!\n",
      "   Fields: 9\n",
      "   - id: Edm.String (key=True, searchable=False)\n",
      "   - title: Edm.String (key=False, searchable=True)\n",
      "   - author: Edm.String (key=False, searchable=True)\n",
      "   - content: Edm.String (key=False, searchable=True)\n",
      "   - category: Edm.String (key=False, searchable=False)\n",
      "   - language: Edm.String (key=False, searchable=False)\n",
      "   - createdDate: Edm.DateTimeOffset (key=False, searchable=False)\n",
      "   - tags: Collection(Edm.String) (key=False, searchable=True)\n",
      "   - contentVector: Collection(Edm.Single) (key=False, searchable=True, dims=1536)\n"
     ]
    }
   ],
   "source": [
    "# Define vector search configuration\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"hnsw-config\",\n",
    "            parameters={\n",
    "                \"m\": 4,  # Number of bi-directional links\n",
    "                \"efConstruction\": 400,  # Size of dynamic candidate list during indexing\n",
    "                \"efSearch\": 500,  # Size of dynamic candidate list during search\n",
    "                \"metric\": \"cosine\"  # Distance metric\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"vector-profile\",\n",
    "            algorithm_configuration_name=\"hnsw-config\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the index schema with vector field\n",
    "index = SearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    fields=[\n",
    "        # Key field (required)\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        \n",
    "        # Searchable text fields\n",
    "        SearchableField(name=\"title\", type=SearchFieldDataType.String,\n",
    "                       sortable=True, filterable=True),\n",
    "        SearchableField(name=\"author\", type=SearchFieldDataType.String,\n",
    "                       filterable=True, facetable=True),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "        \n",
    "        # Filterable/Facetable fields\n",
    "        SimpleField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                   filterable=True, facetable=True, sortable=True),\n",
    "        SimpleField(name=\"language\", type=SearchFieldDataType.String,\n",
    "                   filterable=True, facetable=True),\n",
    "        \n",
    "        # Date field\n",
    "        SimpleField(name=\"createdDate\", type=SearchFieldDataType.DateTimeOffset,\n",
    "                   filterable=True, sortable=True),\n",
    "        \n",
    "        # Collection field for tags\n",
    "        SearchField(name=\"tags\", type=SearchFieldDataType.Collection(SearchFieldDataType.String),\n",
    "                   searchable=True, filterable=True, facetable=True),\n",
    "        \n",
    "        # Vector field for embeddings\n",
    "        SearchField(\n",
    "            name=\"contentVector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=EMBEDDING_DIMENSIONS,\n",
    "            vector_search_profile_name=\"vector-profile\"\n",
    "        ),\n",
    "    ],\n",
    "    vector_search=vector_search\n",
    ")\n",
    "\n",
    "# Create or update the index\n",
    "try:\n",
    "    result = index_client.create_or_update_index(index)\n",
    "    print(f\"‚úÖ Index '{result.name}' created/updated successfully!\")\n",
    "    print(f\"   Fields: {len(result.fields)}\")\n",
    "    for field in result.fields:\n",
    "        vector_info = f\", dims={field.vector_search_dimensions}\" if field.vector_search_dimensions else \"\"\n",
    "        print(f\"   - {field.name}: {field.type} (key={field.key}, searchable={field.searchable}{vector_info})\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f4be4",
   "metadata": {},
   "source": [
    "## 5. Create Data Source Connection\n",
    "\n",
    "Configure a data source pointing to the sample JSON documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7dfbe867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data source 'embedding-demo-files' created/updated successfully!\n",
      "   Type: filesystem\n",
      "   Path: C:\\Projets\\AzureAISimulator\\samples\\IndexerTestNotebook\\data\n"
     ]
    }
   ],
   "source": [
    "# Create a data source connection pointing to local files\n",
    "data_source = SearchIndexerDataSourceConnection(\n",
    "    name=DATA_SOURCE_NAME,\n",
    "    type=\"filesystem\",  # Simulator-specific type for local files\n",
    "    connection_string=str(DATA_PATH),\n",
    "    container=SearchIndexerDataContainer(name=\".\", query=\"*.json\")\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = indexer_client.create_or_update_data_source_connection(data_source)\n",
    "    print(f\"‚úÖ Data source '{result.name}' created/updated successfully!\")\n",
    "    print(f\"   Type: {result.type}\")\n",
    "    print(f\"   Path: {result.connection_string}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating data source: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa176e1",
   "metadata": {},
   "source": [
    "## 6. Create Skillset with Azure OpenAI Embedding Skill\n",
    "\n",
    "Configure a skillset that uses Azure OpenAI to generate embeddings for the document content.\n",
    "\n",
    "> **Note**: The simulator forwards embedding requests to Azure OpenAI. Make sure your Azure OpenAI credentials are configured in `appsettings.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db1f3e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Skillset 'embedding-skillset' created/updated successfully!\n",
      "   Skills: 1\n",
      "   - embedding-skill: #Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\n"
     ]
    }
   ],
   "source": [
    "# Create skillset with Azure OpenAI Embedding skill using REST API\n",
    "# The Azure SDK doesn't have direct support for AzureOpenAIEmbeddingSkill,\n",
    "# so we'll use the REST API directly\n",
    "\n",
    "if AZURE_OPENAI_API_KEY == \"YOUR-AZURE-OPENAI-API-KEY-HERE\":\n",
    "    print(\"‚ö†Ô∏è WARNING: You need to set AZURE_OPENAI_API_KEY above!\")\n",
    "    print(\"   Get your key from Azure Portal ‚Üí Your Azure OpenAI resource ‚Üí Keys and Endpoint\")\n",
    "\n",
    "skillset_payload = {\n",
    "    \"name\": SKILLSET_NAME,\n",
    "    \"description\": \"Skillset to generate embeddings using Azure OpenAI\",\n",
    "    \"skills\": [\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\",\n",
    "            \"name\": \"embedding-skill\",\n",
    "            \"description\": \"Generate embeddings for document title\",\n",
    "            \"context\": \"/document\",\n",
    "            \"resourceUri\": AZURE_OPENAI_ENDPOINT,\n",
    "            \"deploymentId\": AZURE_OPENAI_DEPLOYMENT,\n",
    "            \"apiKey\": AZURE_OPENAI_API_KEY,  # API key passed directly to skillset\n",
    "            \"modelName\": \"text-embedding-3-small\",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\",\n",
    "                    \"source\": \"/document/title\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"embedding\",\n",
    "                    \"targetName\": \"contentEmbedding\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create skillset using REST API\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": ADMIN_API_KEY\n",
    "}\n",
    "\n",
    "url = f\"{SEARCH_ENDPOINT}/skillsets/{SKILLSET_NAME}?api-version=2024-07-01\"\n",
    "\n",
    "try:\n",
    "    response = session.put(url, headers=headers, json=skillset_payload)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    print(f\"‚úÖ Skillset '{result['name']}' created/updated successfully!\")\n",
    "    print(f\"   Skills: {len(result['skills'])}\")\n",
    "    for skill in result['skills']:\n",
    "        print(f\"   - {skill['name']}: {skill['@odata.type']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating skillset: {e}\")\n",
    "    if hasattr(e, 'response') and e.response is not None:\n",
    "        print(f\"   Response: {e.response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f948d",
   "metadata": {},
   "source": [
    "## 7. Create and Run Indexer with Skillset\n",
    "\n",
    "Create an indexer that processes documents, generates embeddings using the skillset, and indexes everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a854167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Indexer 'embedding-indexer' created/updated successfully!\n",
      "   Data Source: embedding-demo-files\n",
      "   Target Index: embedding-demo-docs\n",
      "   Skillset: embedding-skillset\n"
     ]
    }
   ],
   "source": [
    "# Create indexer with skillset using REST API\n",
    "indexer_payload = {\n",
    "    \"name\": INDEXER_NAME,\n",
    "    \"dataSourceName\": DATA_SOURCE_NAME,\n",
    "    \"targetIndexName\": INDEX_NAME,\n",
    "    \"skillsetName\": SKILLSET_NAME,\n",
    "    \"parameters\": {\n",
    "        \"configuration\": {\n",
    "            \"parsingMode\": \"json\"\n",
    "        }\n",
    "    },\n",
    "    \"fieldMappings\": [\n",
    "        {\"sourceFieldName\": \"id\", \"targetFieldName\": \"id\"},\n",
    "        {\"sourceFieldName\": \"title\", \"targetFieldName\": \"title\"},\n",
    "        {\"sourceFieldName\": \"author\", \"targetFieldName\": \"author\"},\n",
    "        {\"sourceFieldName\": \"category\", \"targetFieldName\": \"category\"},\n",
    "        {\"sourceFieldName\": \"tags\", \"targetFieldName\": \"tags\"},\n",
    "        {\"sourceFieldName\": \"createdDate\", \"targetFieldName\": \"createdDate\"},\n",
    "        {\"sourceFieldName\": \"language\", \"targetFieldName\": \"language\"}\n",
    "    ],\n",
    "    \"outputFieldMappings\": [\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/contentEmbedding\",\n",
    "            \"targetFieldName\": \"contentVector\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "url = f\"{SEARCH_ENDPOINT}/indexers/{INDEXER_NAME}?api-version=2024-07-01\"\n",
    "\n",
    "try:\n",
    "    response = session.put(url, headers=headers, json=indexer_payload)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    print(f\"‚úÖ Indexer '{result['name']}' created/updated successfully!\")\n",
    "    print(f\"   Data Source: {result['dataSourceName']}\")\n",
    "    print(f\"   Target Index: {result['targetIndexName']}\")\n",
    "    print(f\"   Skillset: {result['skillsetName']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating indexer: {e}\")\n",
    "    if hasattr(e, 'response') and e.response is not None:\n",
    "        print(f\"   Response: {e.response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "972bdaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Resetting indexer to reprocess all documents...\n",
      "‚úÖ Indexer reset!\n",
      "\n",
      "üöÄ Running indexer...\n",
      "‚úÖ Indexer run triggered!\n",
      "\n",
      "‚è≥ Waiting for indexer to complete (this may take a while for embedding generation)...\n",
      "   Status: success (items: 5)\n",
      "\n",
      "üìä Indexer Execution Results:\n",
      "   Status: success\n",
      "   Items Processed: 5\n",
      "   Items Failed: 0\n"
     ]
    }
   ],
   "source": [
    "# Reset and run the indexer to reprocess all documents\n",
    "print(\"üîÑ Resetting indexer to reprocess all documents...\")\n",
    "\n",
    "try:\n",
    "    reset_url = f\"{SEARCH_ENDPOINT}/indexers/{INDEXER_NAME}/reset?api-version=2024-07-01\"\n",
    "    response = session.post(reset_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    print(\"‚úÖ Indexer reset!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not reset indexer (may not exist yet): {e}\")\n",
    "\n",
    "print(\"\\nüöÄ Running indexer...\")\n",
    "\n",
    "try:\n",
    "    run_url = f\"{SEARCH_ENDPOINT}/indexers/{INDEXER_NAME}/run?api-version=2024-07-01\"\n",
    "    response = session.post(run_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    print(\"‚úÖ Indexer run triggered!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error running indexer: {e}\")\n",
    "\n",
    "# Wait for indexer to complete\n",
    "print(\"\\n‚è≥ Waiting for indexer to complete (this may take a while for embedding generation)...\")\n",
    "max_wait = 90  # seconds - increased for embedding generation\n",
    "wait_interval = 3\n",
    "\n",
    "for i in range(0, max_wait, wait_interval):\n",
    "    time.sleep(wait_interval)\n",
    "    try:\n",
    "        status_url = f\"{SEARCH_ENDPOINT}/indexers/{INDEXER_NAME}/status?api-version=2024-07-01\"\n",
    "        response = session.get(status_url, headers=headers)\n",
    "        status = response.json()\n",
    "        \n",
    "        last_result = status.get('lastResult')\n",
    "        if last_result:\n",
    "            status_val = last_result.get('status', 'unknown')\n",
    "            items = last_result.get('itemsProcessed', 0)\n",
    "            print(f\"   Status: {status_val} (items: {items})\")\n",
    "            if status_val in [\"success\", \"transientFailure\", \"reset\"]:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"   Checking status... ({e})\")\n",
    "\n",
    "# Get final status\n",
    "try:\n",
    "    response = session.get(status_url, headers=headers)\n",
    "    status = response.json()\n",
    "    last_result = status.get('lastResult', {})\n",
    "    \n",
    "    print(f\"\\nüìä Indexer Execution Results:\")\n",
    "    print(f\"   Status: {last_result.get('status', 'unknown')}\")\n",
    "    print(f\"   Items Processed: {last_result.get('itemsProcessed', 0)}\")\n",
    "    print(f\"   Items Failed: {last_result.get('itemsFailed', 0)}\")\n",
    "    \n",
    "    errors = last_result.get('errors', [])\n",
    "    if errors:\n",
    "        print(f\"   Errors:\")\n",
    "        for error in errors[:5]:  # Show first 5 errors\n",
    "            print(f\"      - {error.get('errorMessage', 'Unknown error')}\")\n",
    "    \n",
    "    warnings = last_result.get('warnings', [])\n",
    "    if warnings:\n",
    "        print(f\"   Warnings:\")\n",
    "        for warning in warnings[:3]:\n",
    "            print(f\"      - {warning.get('message', 'Unknown warning')}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error getting status: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7615ad72",
   "metadata": {},
   "source": [
    "## 8. Verify Indexed Documents with Embeddings\n",
    "\n",
    "Check that documents were indexed with their vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "448b62db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Document Count Verification:\n",
      "   Expected: 5 documents\n",
      "   Actual:   5 documents\n",
      "   ‚úÖ doc-001: Introduction to Azure AI Search - Vector dims: 1536\n",
      "   ‚úÖ doc-002: Creating Search Indexes - Vector dims: 1536\n",
      "   ‚úÖ doc-003: Understanding Indexers and Data Sources - Vector dims: 1536\n",
      "   ‚úÖ doc-004: Search Query Syntax Guide - Vector dims: 1536\n",
      "   ‚úÖ doc-005: Security and Access Control - Vector dims: 1536\n",
      "\n",
      "üìä Documents with embeddings: 5/5\n"
     ]
    }
   ],
   "source": [
    "# Create search client to query the index\n",
    "search_client = SearchClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    index_name=INDEX_NAME,\n",
    "    credential=admin_credential,\n",
    "    transport=transport,\n",
    "    connection_verify=False\n",
    ")\n",
    "\n",
    "# Get all documents\n",
    "results = search_client.search(search_text=\"*\", include_total_count=True, select=[\"id\", \"title\", \"category\", \"contentVector\"])\n",
    "results_list = list(results)\n",
    "\n",
    "print(f\"üìä Document Count Verification:\")\n",
    "print(f\"   Expected: 5 documents\")\n",
    "print(f\"   Actual:   {len(results_list)} documents\")\n",
    "\n",
    "# Check for embeddings\n",
    "docs_with_vectors = 0\n",
    "for doc in results_list:\n",
    "    vector = doc.get('contentVector')\n",
    "    has_vector = vector is not None and len(vector) > 0\n",
    "    if has_vector:\n",
    "        docs_with_vectors += 1\n",
    "        vector_preview = str(vector[:5]) + \"...\" if len(vector) > 5 else str(vector)\n",
    "        print(f\"   ‚úÖ {doc['id']}: {doc['title']} - Vector dims: {len(vector)}\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è {doc['id']}: {doc['title']} - No vector\")\n",
    "\n",
    "print(f\"\\nüìä Documents with embeddings: {docs_with_vectors}/{len(results_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c49c5",
   "metadata": {},
   "source": [
    "## 9. Vector Search (Semantic Search)\n",
    "\n",
    "Use vector search to find semantically similar documents. We'll generate a query embedding and search for similar content.\n",
    "\n",
    "> **Note**: For this demo, we'll use a sample query vector. In production, you would generate the query embedding using the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e91ca333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Using vector from document 'doc-001' as query vector\n",
      "   Vector dimensions: 1536\n",
      "   First 5 values: [-0.012323121, -0.022843149, 0.022771502, -0.0055257017, 0.013779923]\n"
     ]
    }
   ],
   "source": [
    "# For demo purposes, we'll use one of the document vectors as a query vector\n",
    "# In production, you would call Azure OpenAI to generate the query embedding\n",
    "\n",
    "# Get a document vector to use as query\n",
    "sample_doc = results_list[0] if results_list else None\n",
    "if sample_doc and sample_doc.get('contentVector'):\n",
    "    query_vector = sample_doc['contentVector']\n",
    "    print(f\"üîç Using vector from document '{sample_doc['id']}' as query vector\")\n",
    "    print(f\"   Vector dimensions: {len(query_vector)}\")\n",
    "    print(f\"   First 5 values: {query_vector[:5]}\")\n",
    "else:\n",
    "    # Create a random vector as fallback (for demo without Azure OpenAI)\n",
    "    query_vector = np.random.rand(EMBEDDING_DIMENSIONS).astype(float).tolist()\n",
    "    print(f\"üîç Using random vector as query (no documents with vectors found)\")\n",
    "    print(f\"   Vector dimensions: {len(query_vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96860cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Vector Search Results:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>doc-001</td>\n",
       "      <td>Introduction to Azure AI Search</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>doc-002</td>\n",
       "      <td>Creating Search Indexes</td>\n",
       "      <td>Tutorial</td>\n",
       "      <td>0.6576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>doc-004</td>\n",
       "      <td>Search Query Syntax Guide</td>\n",
       "      <td>Reference</td>\n",
       "      <td>0.6303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>doc-003</td>\n",
       "      <td>Understanding Indexers and Data Sources</td>\n",
       "      <td>Tutorial</td>\n",
       "      <td>0.6187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>doc-005</td>\n",
       "      <td>Security and Access Control</td>\n",
       "      <td>Security</td>\n",
       "      <td>0.5528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank       ID                                    Title       Category  \\\n",
       "0     1  doc-001          Introduction to Azure AI Search  Documentation   \n",
       "1     2  doc-002                  Creating Search Indexes       Tutorial   \n",
       "2     3  doc-004                Search Query Syntax Guide      Reference   \n",
       "3     4  doc-003  Understanding Indexers and Data Sources       Tutorial   \n",
       "4     5  doc-005              Security and Access Control       Security   \n",
       "\n",
       "    Score  \n",
       "0  1.0000  \n",
       "1  0.6576  \n",
       "2  0.6303  \n",
       "3  0.6187  \n",
       "4  0.5528  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform vector search\n",
    "print(\"üîç Vector Search Results:\\n\")\n",
    "\n",
    "try:\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=query_vector,\n",
    "        k_nearest_neighbors=5,\n",
    "        fields=\"contentVector\"\n",
    "    )\n",
    "    \n",
    "    results = search_client.search(\n",
    "        search_text=None,  # Pure vector search\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\", \"title\", \"category\", \"author\"]\n",
    "    )\n",
    "    \n",
    "    results_list = list(results)\n",
    "    \n",
    "    if results_list:\n",
    "        data = []\n",
    "        for i, doc in enumerate(results_list, 1):\n",
    "            score = doc.get('@search.score', 0)\n",
    "            data.append({\n",
    "                'Rank': i,\n",
    "                'ID': doc['id'],\n",
    "                'Title': doc['title'],\n",
    "                'Category': doc.get('category', 'N/A'),\n",
    "                'Score': f\"{score:.4f}\"\n",
    "            })\n",
    "        \n",
    "        display(pd.DataFrame(data))\n",
    "    else:\n",
    "        print(\"No results found. Make sure documents have vectors indexed.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error performing vector search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca3a9a",
   "metadata": {},
   "source": [
    "## 10. Hybrid Search (Keyword + Vector)\n",
    "\n",
    "Combine traditional keyword search with vector search for best results. The simulator uses Reciprocal Rank Fusion (RRF) to combine results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c74fcb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Hybrid Search Results (keyword + vector):\n",
      "\n",
      "Query: 'Azure search' (text) + vector similarity\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Hybrid Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>doc-001</td>\n",
       "      <td>Introduction to Azure AI Search</td>\n",
       "      <td>Documentation</td>\n",
       "      <td>1.3572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>doc-002</td>\n",
       "      <td>Creating Search Indexes</td>\n",
       "      <td>Tutorial</td>\n",
       "      <td>0.4229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>doc-004</td>\n",
       "      <td>Search Query Syntax Guide</td>\n",
       "      <td>Reference</td>\n",
       "      <td>0.3424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>doc-003</td>\n",
       "      <td>Understanding Indexers and Data Sources</td>\n",
       "      <td>Tutorial</td>\n",
       "      <td>0.3094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>doc-005</td>\n",
       "      <td>Security and Access Control</td>\n",
       "      <td>Security</td>\n",
       "      <td>0.2764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank       ID                                    Title       Category  \\\n",
       "0     1  doc-001          Introduction to Azure AI Search  Documentation   \n",
       "1     2  doc-002                  Creating Search Indexes       Tutorial   \n",
       "2     3  doc-004                Search Query Syntax Guide      Reference   \n",
       "3     4  doc-003  Understanding Indexers and Data Sources       Tutorial   \n",
       "4     5  doc-005              Security and Access Control       Security   \n",
       "\n",
       "  Hybrid Score  \n",
       "0       1.3572  \n",
       "1       0.4229  \n",
       "2       0.3424  \n",
       "3       0.3094  \n",
       "4       0.2764  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Hybrid search combines keyword relevance with semantic similarity using RRF fusion.\n"
     ]
    }
   ],
   "source": [
    "# Perform hybrid search\n",
    "print(\"üîç Hybrid Search Results (keyword + vector):\\n\")\n",
    "print(\"Query: 'Azure search' (text) + vector similarity\\n\")\n",
    "\n",
    "try:\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=query_vector,\n",
    "        k_nearest_neighbors=5,\n",
    "        fields=\"contentVector\"\n",
    "    )\n",
    "    \n",
    "    results = search_client.search(\n",
    "        search_text=\"Azure search\",  # Keyword search\n",
    "        vector_queries=[vector_query],  # Plus vector search\n",
    "        select=[\"id\", \"title\", \"category\", \"author\"],\n",
    "        top=5\n",
    "    )\n",
    "    \n",
    "    results_list = list(results)\n",
    "    \n",
    "    if results_list:\n",
    "        data = []\n",
    "        for i, doc in enumerate(results_list, 1):\n",
    "            score = doc.get('@search.score', 0)\n",
    "            data.append({\n",
    "                'Rank': i,\n",
    "                'ID': doc['id'],\n",
    "                'Title': doc['title'],\n",
    "                'Category': doc.get('category', 'N/A'),\n",
    "                'Hybrid Score': f\"{score:.4f}\"\n",
    "            })\n",
    "        \n",
    "        display(pd.DataFrame(data))\n",
    "        print(\"\\nüí° Hybrid search combines keyword relevance with semantic similarity using RRF fusion.\")\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error performing hybrid search: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78731a",
   "metadata": {},
   "source": [
    "## 11. Compare Search Methods\n",
    "\n",
    "Compare results from keyword-only, vector-only, and hybrid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0baad984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Comparing search methods for: 'machine learning AI'\n",
      "\n",
      "1Ô∏è‚É£ Keyword Search (BM25):\n",
      "   - [doc-001] Introduction to Azure AI Search (score: 0.1875)\n",
      "\n",
      "2Ô∏è‚É£ Vector Search (Semantic):\n",
      "   - [doc-001] Introduction to Azure AI Search (score: 1.0000)\n",
      "   - [doc-002] Creating Search Indexes (score: 0.6576)\n",
      "   - [doc-004] Search Query Syntax Guide (score: 0.6303)\n",
      "\n",
      "3Ô∏è‚É£ Hybrid Search (RRF Fusion):\n",
      "   - [doc-001] Introduction to Azure AI Search (score: 0.5938)\n",
      "   - [doc-002] Creating Search Indexes (score: 0.3288)\n",
      "   - [doc-004] Search Query Syntax Guide (score: 0.3151)\n"
     ]
    }
   ],
   "source": [
    "# Compare different search methods\n",
    "search_query = \"machine learning AI\"\n",
    "\n",
    "print(f\"üîç Comparing search methods for: '{search_query}'\\n\")\n",
    "\n",
    "# 1. Keyword Search\n",
    "print(\"1Ô∏è‚É£ Keyword Search (BM25):\")\n",
    "try:\n",
    "    results = search_client.search(\n",
    "        search_text=search_query,\n",
    "        select=[\"id\", \"title\"],\n",
    "        top=3\n",
    "    )\n",
    "    for doc in results:\n",
    "        print(f\"   - [{doc['id']}] {doc['title']} (score: {doc.get('@search.score', 0):.4f})\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 2. Vector Search\n",
    "print(\"2Ô∏è‚É£ Vector Search (Semantic):\")\n",
    "try:\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=query_vector,\n",
    "        k_nearest_neighbors=3,\n",
    "        fields=\"contentVector\"\n",
    "    )\n",
    "    results = search_client.search(\n",
    "        search_text=None,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\", \"title\"],\n",
    "        top=3\n",
    "    )\n",
    "    for doc in results:\n",
    "        print(f\"   - [{doc['id']}] {doc['title']} (score: {doc.get('@search.score', 0):.4f})\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 3. Hybrid Search\n",
    "print(\"3Ô∏è‚É£ Hybrid Search (RRF Fusion):\")\n",
    "try:\n",
    "    vector_query = VectorizedQuery(\n",
    "        vector=query_vector,\n",
    "        k_nearest_neighbors=3,\n",
    "        fields=\"contentVector\"\n",
    "    )\n",
    "    results = search_client.search(\n",
    "        search_text=search_query,\n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"id\", \"title\"],\n",
    "        top=3\n",
    "    )\n",
    "    for doc in results:\n",
    "        print(f\"   - [{doc['id']}] {doc['title']} (score: {doc.get('@search.score', 0):.4f})\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c2b46",
   "metadata": {},
   "source": [
    "## 12. Cleanup (Optional)\n",
    "\n",
    "Delete all resources created during this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14a9549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Cleanup skipped. Set cleanup = True to delete resources.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this cell to clean up all resources\n",
    "# WARNING: This will delete the index, indexer, skillset, and data source!\n",
    "\n",
    "cleanup = False  # Set to True to enable cleanup\n",
    "\n",
    "if cleanup:\n",
    "    print(\"üßπ Cleaning up resources...\")\n",
    "    \n",
    "    # Delete indexer first\n",
    "    try:\n",
    "        url = f\"{SEARCH_ENDPOINT}/indexers/{INDEXER_NAME}?api-version=2024-07-01\"\n",
    "        session.delete(url, headers=headers)\n",
    "        print(f\"   ‚úÖ Deleted indexer: {INDEXER_NAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not delete indexer: {e}\")\n",
    "    \n",
    "    # Delete skillset\n",
    "    try:\n",
    "        url = f\"{SEARCH_ENDPOINT}/skillsets/{SKILLSET_NAME}?api-version=2024-07-01\"\n",
    "        session.delete(url, headers=headers)\n",
    "        print(f\"   ‚úÖ Deleted skillset: {SKILLSET_NAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not delete skillset: {e}\")\n",
    "    \n",
    "    # Delete data source\n",
    "    try:\n",
    "        indexer_client.delete_data_source_connection(DATA_SOURCE_NAME)\n",
    "        print(f\"   ‚úÖ Deleted data source: {DATA_SOURCE_NAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not delete data source: {e}\")\n",
    "    \n",
    "    # Delete index\n",
    "    try:\n",
    "        index_client.delete_index(INDEX_NAME)\n",
    "        print(f\"   ‚úÖ Deleted index: {INDEX_NAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not delete index: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Cleanup complete!\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Cleanup skipped. Set cleanup = True to delete resources.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96685b14",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "| Feature | Status | Notes |\n",
    "|---------|--------|-------|\n",
    "| Vector Index | ‚úÖ | Created index with `Collection(Edm.Single)` vector field |\n",
    "| HNSW Configuration | ‚úÖ | Configured HNSW algorithm for vector search |\n",
    "| Embedding Skillset | ‚úÖ | Azure OpenAI Embedding skill for generating vectors |\n",
    "| Indexer with Skills | ‚úÖ | Processed documents and generated embeddings |\n",
    "| Vector Search | ‚úÖ | Semantic similarity search using embeddings |\n",
    "| Hybrid Search | ‚úÖ | Combined keyword + vector with RRF fusion |\n",
    "\n",
    "### Key Learnings\n",
    "\n",
    "1. **Vector Fields**: Use `Collection(Edm.Single)` with `vector_search_dimensions` for embeddings\n",
    "2. **HNSW Algorithm**: Configure M, efConstruction, and efSearch for performance tuning\n",
    "3. **Embedding Skill**: Azure OpenAI generates 1536-dimensional embeddings (text-embedding-ada-002)\n",
    "4. **Hybrid Search**: RRF fusion combines keyword relevance with semantic similarity\n",
    "5. **Output Field Mappings**: Map skillset outputs (embeddings) to index vector fields\n",
    "\n",
    "The Azure AI Search Simulator successfully replicates the vector search and embedding functionality of Azure AI Search!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
