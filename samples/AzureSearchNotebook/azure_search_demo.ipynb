{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c3831aa",
   "metadata": {},
   "source": [
    "# Azure AI Search Simulator - Python SDK Demo\n",
    "\n",
    "This notebook demonstrates how to use the **official Azure AI Search Python SDK** with the local **Azure AI Search Simulator**.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Start the Azure AI Search Simulator with HTTPS** (required by Azure SDK):\n",
    "   ```bash\n",
    "   cd src/AzureAISearchSimulator.Api && dotnet run --urls \"https://localhost:7250\"\n",
    "   ```\n",
    "\n",
    "2. **Start the Custom Skills API** (optional, for skillset demo):\n",
    "   ```bash\n",
    "   cd samples/CustomSkillSample && dotnet run\n",
    "   ```\n",
    "\n",
    "3. **Install Python dependencies**:\n",
    "   ```bash\n",
    "   pip install azure-search-documents httpx requests pandas\n",
    "   ```\n",
    "\n",
    "## What This Notebook Covers\n",
    "\n",
    "- Creating search indexes with the **official Azure SDK**\n",
    "- Setting up data sources for local file system\n",
    "- Configuring custom Web API skills in skillsets\n",
    "- Creating indexers with change detection\n",
    "- Searching and displaying results\n",
    "\n",
    "> ‚ö†Ô∏è **Note**: The Azure SDK requires HTTPS. The simulator must be started with `--urls \"https://localhost:7250\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18dd95c",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "472507b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install azure-search-documents requests pandas\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import urllib3\n",
    "from pathlib import Path\n",
    "\n",
    "# Azure AI Search SDK imports\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerSkillset,\n",
    "    WebApiSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    FieldMapping,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    SplitSkill,\n",
    ")\n",
    "\n",
    "# For displaying results\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Suppress SSL warnings for local development\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41422ca",
   "metadata": {},
   "source": [
    "## 2. Initialize Azure AI Search Clients\n",
    "\n",
    "Configure the connection to the local Azure AI Search Simulator. The simulator runs on `http://localhost:5250` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb7c8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Azure AI Search Simulator at https://localhost:7250\n",
      "   Index Client: SearchIndexClient\n",
      "   Indexer Client: SearchIndexerClient\n",
      "   ‚ö†Ô∏è  SSL verification disabled for local development\n"
     ]
    }
   ],
   "source": [
    "# Configuration for Azure AI Search Simulator\n",
    "# NOTE: The Azure SDK requires HTTPS. Run the simulator with HTTPS:\n",
    "#   dotnet run --urls \"https://localhost:7250\"\n",
    "\n",
    "SEARCH_ENDPOINT = \"https://localhost:7250\"  # HTTPS required for Azure SDK\n",
    "ADMIN_API_KEY = \"admin-key-12345\"\n",
    "QUERY_API_KEY = \"query-key-67890\"\n",
    "\n",
    "# Index and resource names\n",
    "INDEX_NAME = \"pdf-documents\"\n",
    "DATA_SOURCE_NAME = \"local-pdf-files\"\n",
    "SKILLSET_NAME = \"pdf-enrichment\"\n",
    "INDEXER_NAME = \"pdf-indexer\"\n",
    "\n",
    "# Custom Skill API (from CustomSkillSample project)\n",
    "CUSTOM_SKILL_BASE_URL = \"http://localhost:5260\"\n",
    "\n",
    "# Create credentials\n",
    "admin_credential = AzureKeyCredential(ADMIN_API_KEY)\n",
    "query_credential = AzureKeyCredential(QUERY_API_KEY)\n",
    "\n",
    "# Configure HTTP client to skip SSL certificate validation for local development\n",
    "# This is required because the simulator uses a self-signed dev certificate\n",
    "import requests as req_lib\n",
    "from azure.core.pipeline.transport import RequestsTransport\n",
    "\n",
    "# Create a requests session with SSL verification disabled\n",
    "session = req_lib.Session()\n",
    "session.verify = False\n",
    "\n",
    "# Create custom transport - pass connection_verify=False explicitly\n",
    "transport = RequestsTransport(session=session, connection_verify=False)\n",
    "\n",
    "# Create clients for index management\n",
    "# Note: We also pass connection_verify=False to the client kwargs\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    credential=admin_credential,\n",
    "    transport=transport,\n",
    "    connection_verify=False\n",
    ")\n",
    "\n",
    "# Create client for indexer/data source/skillset management  \n",
    "indexer_client = SearchIndexerClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    credential=admin_credential,\n",
    "    transport=transport,\n",
    "    connection_verify=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Connected to Azure AI Search Simulator at {SEARCH_ENDPOINT}\")\n",
    "print(f\"   Index Client: {type(index_client).__name__}\")\n",
    "print(f\"   Indexer Client: {type(indexer_client).__name__}\")\n",
    "print(f\"   ‚ö†Ô∏è  SSL verification disabled for local development\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fae64db",
   "metadata": {},
   "source": [
    "## 3. Download Sample PDF Files and Metadata\n",
    "\n",
    "Download sample PDF documents from Azure AI Search samples repository. These are commonly used for demos and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for sample documents\n",
    "DOCS_PATH = Path(\"./sample-documents\")\n",
    "DOCS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Sample PDF URLs from Azure cognitive-search-sample-data repository\n",
    "# Using English documents from the health-plan folder\n",
    "SAMPLE_PDFS = {\n",
    "    \"employee-handbook\": {\n",
    "        \"url\": \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/main/health-plan/employee_handbook.pdf\",\n",
    "        \"title\": \"Employee Handbook\",\n",
    "        \"category\": \"HR\",\n",
    "        \"department\": \"Human Resources\"\n",
    "    },\n",
    "    \"benefit-options\": {\n",
    "        \"url\": \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/main/health-plan/Benefit_Options.pdf\",\n",
    "        \"title\": \"Benefit Options\",\n",
    "        \"category\": \"Benefits\",\n",
    "        \"department\": \"Human Resources\"\n",
    "    },\n",
    "    \"perks-plus\": {\n",
    "        \"url\": \"https://raw.githubusercontent.com/Azure-Samples/azure-search-sample-data/main/health-plan/PerksPlus.pdf\",\n",
    "        \"title\": \"Perks Plus Program\",\n",
    "        \"category\": \"Benefits\",\n",
    "        \"department\": \"Human Resources\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def download_file(url: str, filepath: Path) -> bool:\n",
    "    \"\"\"Download a file from URL to local path.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        filepath.write_bytes(response.content)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Failed to download {url}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Download PDFs and create metadata JSON files\n",
    "downloaded_files = []\n",
    "for doc_id, doc_info in SAMPLE_PDFS.items():\n",
    "    pdf_path = DOCS_PATH / f\"{doc_id}.pdf\"\n",
    "    json_path = DOCS_PATH / f\"{doc_id}.json\"\n",
    "    \n",
    "    # Download PDF if not exists\n",
    "    if not pdf_path.exists():\n",
    "        print(f\"üì• Downloading {doc_info['title']}...\")\n",
    "        if download_file(doc_info[\"url\"], pdf_path):\n",
    "            print(f\"   ‚úÖ Saved to {pdf_path}\")\n",
    "            downloaded_files.append(pdf_path)\n",
    "    else:\n",
    "        print(f\"üìÑ {doc_info['title']} already exists\")\n",
    "        downloaded_files.append(pdf_path)\n",
    "    \n",
    "    # Create metadata JSON file\n",
    "    metadata = {\n",
    "        \"id\": doc_id,\n",
    "        \"title\": doc_info[\"title\"],\n",
    "        \"category\": doc_info[\"category\"],\n",
    "        \"department\": doc_info[\"department\"],\n",
    "        \"source_file\": str(pdf_path.name),\n",
    "        \"last_modified\": \"2026-01-24T10:00:00Z\"\n",
    "    }\n",
    "    json_path.write_text(json.dumps(metadata, indent=2))\n",
    "    print(f\"   üìã Metadata saved to {json_path}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(downloaded_files)} PDF files ready in {DOCS_PATH.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7f198",
   "metadata": {},
   "source": [
    "## 4. Create a Simple Search Index\n",
    "\n",
    "Define the search index schema with fields for document content, metadata, and enrichments from custom skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a6956e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleted existing index 'pdf-documents'\n",
      "‚úÖ Created index 'pdf-documents' with 13 fields\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Searchable</th>\n",
       "      <th>Filterable</th>\n",
       "      <th>Facetable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>content</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td>‚úì</td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>metadata_storage_path</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>metadata_storage_name</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wordCount</td>\n",
       "      <td>Edm.Int32</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sentenceCount</td>\n",
       "      <td>Edm.Int32</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>keywords</td>\n",
       "      <td>Collection(Edm.String)</td>\n",
       "      <td>‚úì</td>\n",
       "      <td>‚úì</td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sentiment</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td>‚úì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sentimentScore</td>\n",
       "      <td>Edm.Double</td>\n",
       "      <td></td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>summary</td>\n",
       "      <td>Edm.String</td>\n",
       "      <td>‚úì</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Field Name                    Type Searchable Filterable  \\\n",
       "0                      id              Edm.String                     ‚úì   \n",
       "1                 content              Edm.String          ‚úì              \n",
       "2                   title              Edm.String          ‚úì          ‚úì   \n",
       "3                category              Edm.String                     ‚úì   \n",
       "4              department              Edm.String                     ‚úì   \n",
       "5   metadata_storage_path              Edm.String                     ‚úì   \n",
       "6   metadata_storage_name              Edm.String                     ‚úì   \n",
       "7               wordCount               Edm.Int32                     ‚úì   \n",
       "8           sentenceCount               Edm.Int32                     ‚úì   \n",
       "9                keywords  Collection(Edm.String)          ‚úì          ‚úì   \n",
       "10              sentiment              Edm.String                     ‚úì   \n",
       "11         sentimentScore              Edm.Double                     ‚úì   \n",
       "12                summary              Edm.String          ‚úì              \n",
       "\n",
       "   Facetable  \n",
       "0             \n",
       "1             \n",
       "2             \n",
       "3          ‚úì  \n",
       "4          ‚úì  \n",
       "5             \n",
       "6             \n",
       "7             \n",
       "8             \n",
       "9          ‚úì  \n",
       "10         ‚úì  \n",
       "11            \n",
       "12            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the search index schema\n",
    "index = SearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    fields=[\n",
    "        # Key field (required)\n",
    "        SimpleField(\n",
    "            name=\"id\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            key=True,\n",
    "            filterable=True\n",
    "        ),\n",
    "        \n",
    "        # Document content - searchable\n",
    "        SearchableField(\n",
    "            name=\"content\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            analyzer_name=\"en.lucene\"\n",
    "        ),\n",
    "        \n",
    "        # Metadata fields\n",
    "        SearchableField(\n",
    "            name=\"title\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"category\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True,\n",
    "            facetable=True\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"department\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True,\n",
    "            facetable=True\n",
    "        ),\n",
    "        \n",
    "        # Storage metadata (populated by indexer)\n",
    "        SimpleField(\n",
    "            name=\"metadata_storage_path\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"metadata_storage_name\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        \n",
    "        # Fields populated by custom skills\n",
    "        SimpleField(\n",
    "            name=\"wordCount\",\n",
    "            type=SearchFieldDataType.Int32,\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"sentenceCount\",\n",
    "            type=SearchFieldDataType.Int32,\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        # NOTE: For SearchableField with Collection(Edm.String), use collection=True parameter\n",
    "        # The type parameter is ignored by SearchableField and defaults to Edm.String\n",
    "        SearchableField(\n",
    "            name=\"keywords\",\n",
    "            collection=True,  # This makes it Collection(Edm.String)\n",
    "            filterable=True,\n",
    "            facetable=True\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"sentiment\",\n",
    "            type=SearchFieldDataType.String,\n",
    "            filterable=True,\n",
    "            facetable=True\n",
    "        ),\n",
    "        SimpleField(\n",
    "            name=\"sentimentScore\",\n",
    "            type=SearchFieldDataType.Double,\n",
    "            filterable=True,\n",
    "            sortable=True\n",
    "        ),\n",
    "        SearchableField(\n",
    "            name=\"summary\",\n",
    "            type=SearchFieldDataType.String\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Try to create the index - if it exists, delete and recreate\n",
    "from azure.core.exceptions import ResourceExistsError, ResourceNotFoundError\n",
    "\n",
    "try:\n",
    "    # First try to delete any existing index\n",
    "    index_client.delete_index(INDEX_NAME)\n",
    "    print(f\"üóëÔ∏è Deleted existing index '{INDEX_NAME}'\")\n",
    "except ResourceNotFoundError:\n",
    "    print(f\"‚ÑπÔ∏è Index '{INDEX_NAME}' does not exist, will create new\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not delete index: {e}\")\n",
    "\n",
    "# Create the index\n",
    "try:\n",
    "    result = index_client.create_index(index)\n",
    "    print(f\"‚úÖ Created index '{result.name}' with {len(result.fields)} fields\")\n",
    "except ResourceExistsError:\n",
    "    # If it still exists, try to get it\n",
    "    result = index_client.get_index(INDEX_NAME)\n",
    "    print(f\"‚ÑπÔ∏è Using existing index '{result.name}' with {len(result.fields)} fields\")\n",
    "\n",
    "# Display field information\n",
    "field_info = [(f.name, str(f.type), \"‚úì\" if getattr(f, 'searchable', False) else \"\", \n",
    "               \"‚úì\" if getattr(f, 'filterable', False) else \"\",\n",
    "               \"‚úì\" if getattr(f, 'facetable', False) else \"\") \n",
    "              for f in result.fields]\n",
    "df = pd.DataFrame(field_info, columns=[\"Field Name\", \"Type\", \"Searchable\", \"Filterable\", \"Facetable\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7cd788",
   "metadata": {},
   "source": [
    "## 5. Create Data Source for Local File System\n",
    "\n",
    "Configure a data source that points to the local folder containing PDF documents. The simulator supports `filesystem` type for local development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the sample documents folder\n",
    "docs_absolute_path = str(DOCS_PATH.absolute())\n",
    "\n",
    "# Create data source connection for local file system\n",
    "# Note: The simulator uses \"filesystem\" type for local paths\n",
    "data_source = SearchIndexerDataSourceConnection(\n",
    "    name=DATA_SOURCE_NAME,\n",
    "    type=\"filesystem\",  # Simulator-specific type for local files\n",
    "    connection_string=f\"path={docs_absolute_path}\",\n",
    "    container=SearchIndexerDataContainer(\n",
    "        name=\".\"  # Use \".\" for root folder (files are directly in sample-documents)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Delete existing data source if it exists\n",
    "try:\n",
    "    indexer_client.delete_data_source_connection(DATA_SOURCE_NAME)\n",
    "    print(f\"üóëÔ∏è Deleted existing data source '{DATA_SOURCE_NAME}'\")\n",
    "except ResourceNotFoundError:\n",
    "    print(f\"‚ÑπÔ∏è Data source '{DATA_SOURCE_NAME}' does not exist, will create new\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not delete data source: {e}\")\n",
    "\n",
    "# Create the data source\n",
    "try:\n",
    "    result = indexer_client.create_data_source_connection(data_source)\n",
    "    print(f\"‚úÖ Created data source '{result.name}'\")\n",
    "    print(f\"   Type: {result.type}\")\n",
    "    print(f\"   Path: {docs_absolute_path}\")\n",
    "except ResourceExistsError:\n",
    "    # Data source exists, try to get it\n",
    "    result = indexer_client.get_data_source_connection(DATA_SOURCE_NAME)\n",
    "    print(f\"‚ÑπÔ∏è Using existing data source '{result.name}'\")\n",
    "    print(f\"   Type: {result.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c4b005",
   "metadata": {},
   "source": [
    "## 6. Configure Custom Skills in Skillset\n",
    "\n",
    "Create a skillset that uses the **Custom Web API Skills** from the `CustomSkillSample` project. These skills provide:\n",
    "- **Text Stats**: Word count, sentence count, character count\n",
    "- **Keyword Extraction**: Extract important keywords\n",
    "- **Sentiment Analysis**: Detect positive/negative/neutral sentiment\n",
    "- **Summarization**: Create extractive summaries\n",
    "\n",
    "> ‚ö†Ô∏è Make sure the CustomSkillSample is running on `http://localhost:5260`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom skills using the CustomSkillSample API\n",
    "skillset = SearchIndexerSkillset(\n",
    "    name=SKILLSET_NAME,\n",
    "    description=\"Skillset using custom Web API skills for PDF enrichment\",\n",
    "    skills=[\n",
    "        # Skill 1: Text Statistics (word count, sentence count)\n",
    "        WebApiSkill(\n",
    "            name=\"text-stats-skill\",\n",
    "            description=\"Counts words, sentences, and characters in the document\",\n",
    "            uri=f\"{CUSTOM_SKILL_BASE_URL}/api/skills/text-stats\",\n",
    "            http_method=\"POST\",\n",
    "            timeout=\"PT30S\",\n",
    "            batch_size=10,\n",
    "            context=\"/document\",\n",
    "            inputs=[\n",
    "                InputFieldMappingEntry(name=\"text\", source=\"/document/content\")\n",
    "            ],\n",
    "            outputs=[\n",
    "                OutputFieldMappingEntry(name=\"wordCount\", target_name=\"wordCount\"),\n",
    "                OutputFieldMappingEntry(name=\"sentenceCount\", target_name=\"sentenceCount\")\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "        # Skill 2: Keyword Extraction\n",
    "        WebApiSkill(\n",
    "            name=\"keywords-skill\",\n",
    "            description=\"Extracts keywords from document content\",\n",
    "            uri=f\"{CUSTOM_SKILL_BASE_URL}/api/skills/extract-keywords\",\n",
    "            http_method=\"POST\",\n",
    "            timeout=\"PT30S\",\n",
    "            batch_size=10,\n",
    "            context=\"/document\",\n",
    "            inputs=[\n",
    "                InputFieldMappingEntry(name=\"text\", source=\"/document/content\")\n",
    "            ],\n",
    "            outputs=[\n",
    "                OutputFieldMappingEntry(name=\"keywords\", target_name=\"keywords\")\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "        # Skill 3: Sentiment Analysis\n",
    "        WebApiSkill(\n",
    "            name=\"sentiment-skill\",\n",
    "            description=\"Analyzes document sentiment\",\n",
    "            uri=f\"{CUSTOM_SKILL_BASE_URL}/api/skills/analyze-sentiment\",\n",
    "            http_method=\"POST\",\n",
    "            timeout=\"PT30S\",\n",
    "            batch_size=10,\n",
    "            context=\"/document\",\n",
    "            inputs=[\n",
    "                InputFieldMappingEntry(name=\"text\", source=\"/document/content\")\n",
    "            ],\n",
    "            outputs=[\n",
    "                OutputFieldMappingEntry(name=\"sentiment\", target_name=\"sentiment\"),\n",
    "                OutputFieldMappingEntry(name=\"score\", target_name=\"sentimentScore\")\n",
    "            ]\n",
    "        ),\n",
    "        \n",
    "        # Skill 4: Summarization\n",
    "        WebApiSkill(\n",
    "            name=\"summarize-skill\",\n",
    "            description=\"Creates an extractive summary\",\n",
    "            uri=f\"{CUSTOM_SKILL_BASE_URL}/api/skills/summarize\",\n",
    "            http_method=\"POST\",\n",
    "            timeout=\"PT30S\",\n",
    "            batch_size=10,\n",
    "            context=\"/document\",\n",
    "            inputs=[\n",
    "                InputFieldMappingEntry(name=\"text\", source=\"/document/content\")\n",
    "            ],\n",
    "            outputs=[\n",
    "                OutputFieldMappingEntry(name=\"summary\", target_name=\"summary\")\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Delete existing skillset if it exists\n",
    "try:\n",
    "    indexer_client.delete_skillset(SKILLSET_NAME)\n",
    "    print(f\"üóëÔ∏è Deleted existing skillset '{SKILLSET_NAME}'\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create the skillset\n",
    "result = indexer_client.create_skillset(skillset)\n",
    "print(f\"‚úÖ Created skillset '{result.name}' with {len(result.skills)} skills:\")\n",
    "for skill in result.skills:\n",
    "    print(f\"   ‚Ä¢ {skill.name}: {skill.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837e737",
   "metadata": {},
   "source": [
    "## 7. Create Indexer with Field Mappings\n",
    "\n",
    "Create an indexer that:\n",
    "1. Reads PDF files from the data source\n",
    "2. Extracts text content (document cracking)\n",
    "3. Applies the custom skills from the skillset\n",
    "4. Maps enriched fields to the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the indexer\n",
    "indexer = SearchIndexer(\n",
    "    name=INDEXER_NAME,\n",
    "    description=\"Indexer for PDF documents with custom skill enrichment\",\n",
    "    data_source_name=DATA_SOURCE_NAME,\n",
    "    target_index_name=INDEX_NAME,\n",
    "    skillset_name=SKILLSET_NAME,\n",
    "    \n",
    "    # Field mappings: source data -> index fields\n",
    "    field_mappings=[\n",
    "        FieldMapping(source_field_name=\"metadata_storage_path\", target_field_name=\"id\"),\n",
    "        FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"metadata_storage_name\"),\n",
    "        FieldMapping(source_field_name=\"metadata_storage_path\", target_field_name=\"metadata_storage_path\")\n",
    "    ],\n",
    "    \n",
    "    # Output field mappings: skill outputs -> index fields\n",
    "    output_field_mappings=[\n",
    "        FieldMapping(source_field_name=\"/document/wordCount\", target_field_name=\"wordCount\"),\n",
    "        FieldMapping(source_field_name=\"/document/sentenceCount\", target_field_name=\"sentenceCount\"),\n",
    "        FieldMapping(source_field_name=\"/document/keywords\", target_field_name=\"keywords\"),\n",
    "        FieldMapping(source_field_name=\"/document/sentiment\", target_field_name=\"sentiment\"),\n",
    "        FieldMapping(source_field_name=\"/document/sentimentScore\", target_field_name=\"sentimentScore\"),\n",
    "        FieldMapping(source_field_name=\"/document/summary\", target_field_name=\"summary\")\n",
    "    ],\n",
    "    \n",
    "    # Indexing parameters\n",
    "    parameters=IndexingParameters(\n",
    "        configuration=IndexingParametersConfiguration(\n",
    "            parsing_mode=\"default\",  # Use default for PDF cracking\n",
    "            data_to_extract=\"contentAndMetadata\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Delete existing indexer if it exists\n",
    "try:\n",
    "    indexer_client.delete_indexer(INDEXER_NAME)\n",
    "    print(f\"üóëÔ∏è Deleted existing indexer '{INDEXER_NAME}'\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create the indexer\n",
    "result = indexer_client.create_indexer(indexer)\n",
    "print(f\"‚úÖ Created indexer '{result.name}'\")\n",
    "print(f\"   Data Source: {result.data_source_name}\")\n",
    "print(f\"   Target Index: {result.target_index_name}\")\n",
    "print(f\"   Skillset: {result.skillset_name}\")\n",
    "print(f\"   Field Mappings: {len(result.field_mappings)}\")\n",
    "print(f\"   Output Field Mappings: {len(result.output_field_mappings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0be212",
   "metadata": {},
   "source": [
    "## 8. Run Indexer and Monitor Status\n",
    "\n",
    "Execute the indexer to process PDF documents and wait for completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# First verify the indexer exists\n",
    "try:\n",
    "    indexer_client.get_indexer(INDEXER_NAME)\n",
    "    print(f\"‚úÖ Found indexer '{INDEXER_NAME}'\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Indexer '{INDEXER_NAME}' not found. Please run the 'Create Indexer' cell first.\")\n",
    "    print(f\"   Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# Run the indexer\n",
    "print(\"üöÄ Running indexer...\")\n",
    "indexer_client.run_indexer(INDEXER_NAME)\n",
    "\n",
    "# Wait and check status\n",
    "last_result = None\n",
    "for i in range(10):\n",
    "    time.sleep(2)\n",
    "    status = indexer_client.get_indexer_status(INDEXER_NAME)\n",
    "    last_result = status.last_result\n",
    "    \n",
    "    if last_result:\n",
    "        print(f\"   Status: {last_result.status}\")\n",
    "        if last_result.status in [\"success\", \"transientFailure\", \"reset\"]:\n",
    "            break\n",
    "        if last_result.status == \"inProgress\":\n",
    "            # Azure SDK uses item_count, not items_processed\n",
    "            print(f\"   Items processed: {last_result.item_count or 0}\")\n",
    "    else:\n",
    "        print(f\"   Waiting for indexer to start... ({i+1}/10)\")\n",
    "\n",
    "# Display final status\n",
    "if last_result:\n",
    "    print(f\"\\nüìä Indexer Execution Results:\")\n",
    "    print(f\"   Status: {last_result.status}\")\n",
    "    print(f\"   Start Time: {last_result.start_time}\")\n",
    "    print(f\"   End Time: {last_result.end_time}\")\n",
    "    # Azure SDK uses item_count and failed_item_count\n",
    "    print(f\"   Items Processed: {last_result.item_count}\")\n",
    "    print(f\"   Items Failed: {last_result.failed_item_count}\")\n",
    "    \n",
    "    if last_result.errors:\n",
    "        print(f\"\\n‚ö†Ô∏è Errors:\")\n",
    "        for error in last_result.errors[:5]:\n",
    "            print(f\"   ‚Ä¢ {error.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56dc50e",
   "metadata": {},
   "source": [
    "## 9. Alternative: Push Documents Directly (Without Indexer)\n",
    "\n",
    "If the indexer isn't available or you prefer the **push model**, you can upload documents directly to the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37f9c462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded 3 documents to index 'pdf-documents'\n",
      "   ‚úì doc-handbook: 200\n",
      "   ‚úì doc-benefits: 200\n",
      "   ‚úì doc-product-manual: 200\n"
     ]
    }
   ],
   "source": [
    "# Create a search client for document operations (using official SDK)\n",
    "search_client = SearchClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    index_name=INDEX_NAME,\n",
    "    credential=admin_credential,\n",
    "    transport=transport,\n",
    "    connection_verify=False\n",
    ")\n",
    "\n",
    "# Sample documents to upload (simulating enriched content)\n",
    "sample_documents = [\n",
    "    {\n",
    "        \"id\": \"doc-handbook\",\n",
    "        \"title\": \"Employee Handbook\",\n",
    "        \"content\": \"Welcome to our company! This handbook covers company policies, employee benefits, vacation policies, and workplace guidelines. All employees are expected to follow these guidelines. Our company values integrity, teamwork, and innovation.\",\n",
    "        \"category\": \"HR\",\n",
    "        \"department\": \"Human Resources\",\n",
    "        \"metadata_storage_path\": \"/documents/employee-handbook.pdf\",\n",
    "        \"metadata_storage_name\": \"employee-handbook.pdf\",\n",
    "        \"wordCount\": 42,\n",
    "        \"sentenceCount\": 4,\n",
    "        \"keywords\": [\"company\", \"policies\", \"employee\", \"benefits\", \"handbook\"],\n",
    "        \"sentiment\": \"positive\",\n",
    "        \"sentimentScore\": 0.75,\n",
    "        \"summary\": \"This handbook covers company policies, employee benefits, vacation policies, and workplace guidelines.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc-benefits\",\n",
    "        \"title\": \"Health Plan Benefits\",\n",
    "        \"content\": \"Our health plan provides comprehensive medical coverage including dental and vision. Employees can choose from multiple plan options. Coverage begins on your first day of employment. Family coverage is also available at competitive rates.\",\n",
    "        \"category\": \"Benefits\",\n",
    "        \"department\": \"Human Resources\",\n",
    "        \"metadata_storage_path\": \"/documents/health-plan.pdf\",\n",
    "        \"metadata_storage_name\": \"health-plan.pdf\",\n",
    "        \"wordCount\": 38,\n",
    "        \"sentenceCount\": 4,\n",
    "        \"keywords\": [\"health\", \"plan\", \"coverage\", \"medical\", \"dental\", \"vision\"],\n",
    "        \"sentiment\": \"positive\",\n",
    "        \"sentimentScore\": 0.82,\n",
    "        \"summary\": \"Our health plan provides comprehensive medical coverage including dental and vision.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc-product-manual\",\n",
    "        \"title\": \"Product User Manual\",\n",
    "        \"content\": \"This manual provides instructions for using our product safely and effectively. Please read all warnings before operating the device. The product comes with a one-year warranty. Contact support for any technical issues.\",\n",
    "        \"category\": \"Documentation\",\n",
    "        \"department\": \"Product\",\n",
    "        \"metadata_storage_path\": \"/documents/product-manual.pdf\",\n",
    "        \"metadata_storage_name\": \"product-manual.pdf\",\n",
    "        \"wordCount\": 35,\n",
    "        \"sentenceCount\": 4,\n",
    "        \"keywords\": [\"manual\", \"product\", \"instructions\", \"warranty\", \"support\"],\n",
    "        \"sentiment\": \"neutral\",\n",
    "        \"sentimentScore\": 0.55,\n",
    "        \"summary\": \"This manual provides instructions for using our product safely and effectively.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Upload documents using official SDK\n",
    "result = search_client.upload_documents(documents=sample_documents)\n",
    "print(f\"‚úÖ Uploaded {len(sample_documents)} documents to index '{INDEX_NAME}'\")\n",
    "\n",
    "# Display upload results\n",
    "for r in result:\n",
    "    status = \"‚úì\" if r.succeeded else \"‚úó\"\n",
    "    print(f\"   {status} {r.key}: {r.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b288f",
   "metadata": {},
   "source": [
    "## 10. Test Search Queries\n",
    "\n",
    "Now let's search the index with various query types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display search results\n",
    "def display_results(results, query_description):\n",
    "    \"\"\"Display search results in a formatted table.\"\"\"\n",
    "    print(f\"\\nüîç {query_description}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    docs = []\n",
    "    for result in results:\n",
    "        docs.append({\n",
    "            \"Score\": f\"{result['@search.score']:.4f}\" if '@search.score' in result else \"N/A\",\n",
    "            \"Title\": result.get(\"title\", \"N/A\"),\n",
    "            \"Category\": result.get(\"category\", \"N/A\"),\n",
    "            \"Sentiment\": result.get(\"sentiment\", \"N/A\"),\n",
    "            \"Words\": result.get(\"wordCount\", \"N/A\")\n",
    "        })\n",
    "    \n",
    "    if docs:\n",
    "        df = pd.DataFrame(docs)\n",
    "        display(df)\n",
    "        print(f\"\\nüìÑ Found {len(docs)} documents\")\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48733e6",
   "metadata": {},
   "source": [
    "### 10.1 Simple Text Search\n",
    "\n",
    "Search for documents containing specific keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text search\n",
    "results = search_client.search(\n",
    "    search_text=\"employee benefits\",\n",
    "    include_total_count=True\n",
    ")\n",
    "\n",
    "display_results(results, \"Search: 'employee benefits'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc6c00b",
   "metadata": {},
   "source": [
    "### 10.2 Filtered Search\n",
    "\n",
    "Search with OData filter expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e487df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered search - find HR documents with positive sentiment\n",
    "results = search_client.search(\n",
    "    search_text=\"*\",\n",
    "    filter=\"department eq 'Human Resources' and sentiment eq 'positive'\",\n",
    "    include_total_count=True\n",
    ")\n",
    "\n",
    "display_results(results, \"Filter: department='Human Resources' AND sentiment='positive'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344f217",
   "metadata": {},
   "source": [
    "### 10.3 Faceted Search\n",
    "\n",
    "Get facet counts for categories and sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985fe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faceted search\n",
    "results = search_client.search(\n",
    "    search_text=\"*\",\n",
    "    facets=[\"category\", \"department\", \"sentiment\"],\n",
    "    include_total_count=True\n",
    ")\n",
    "\n",
    "# Convert to list to get facets\n",
    "results_list = list(results)\n",
    "\n",
    "print(\"üìä Facet Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display facets\n",
    "facets = results.get_facets()\n",
    "if facets:\n",
    "    for facet_name, facet_values in facets.items():\n",
    "        print(f\"\\nüìå {facet_name}:\")\n",
    "        for fv in facet_values:\n",
    "            print(f\"   ‚Ä¢ {fv['value']}: {fv['count']} documents\")\n",
    "else:\n",
    "    print(\"No facets returned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb977697",
   "metadata": {},
   "source": [
    "### 10.4 Search with Sorting\n",
    "\n",
    "Sort results by sentiment score (descending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d503a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with sorting by sentiment score\n",
    "results = search_client.search(\n",
    "    search_text=\"*\",\n",
    "    order_by=[\"sentimentScore desc\"],\n",
    "    select=[\"title\", \"category\", \"sentiment\", \"sentimentScore\", \"wordCount\"],\n",
    "    include_total_count=True\n",
    ")\n",
    "\n",
    "print(\"üîç All Documents Sorted by Sentiment Score (Highest First)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "docs = []\n",
    "for result in results:\n",
    "    docs.append({\n",
    "        \"Title\": result.get(\"title\"),\n",
    "        \"Category\": result.get(\"category\"),\n",
    "        \"Sentiment\": result.get(\"sentiment\"),\n",
    "        \"Score\": f\"{result.get('sentimentScore', 0):.2f}\",\n",
    "        \"Words\": result.get(\"wordCount\")\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(docs)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a574c5f",
   "metadata": {},
   "source": [
    "### 10.5 Search with Highlighting\n",
    "\n",
    "Get search results with hit highlighting to show matching terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with highlighting\n",
    "results = search_client.search(\n",
    "    search_text=\"coverage health\",\n",
    "    highlight_fields=\"content,summary\",\n",
    "    highlight_pre_tag=\"<mark>\",\n",
    "    highlight_post_tag=\"</mark>\",\n",
    "    include_total_count=True\n",
    ")\n",
    "\n",
    "print(\"üîç Search: 'coverage health' with Highlighting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"\\nüìÑ {result.get('title')}\")\n",
    "    print(f\"   Score: {result.get('@search.score', 'N/A')}\")\n",
    "    \n",
    "    # Display highlights if available\n",
    "    highlights = result.get(\"@search.highlights\", {})\n",
    "    if highlights:\n",
    "        for field, snippets in highlights.items():\n",
    "            print(f\"   {field} highlights:\")\n",
    "            for snippet in snippets[:2]:\n",
    "                # Convert HTML marks to console-friendly format\n",
    "                display_snippet = snippet.replace(\"<mark>\", \"**\").replace(\"</mark>\", \"**\")\n",
    "                print(f\"      ‚Ä¢ ...{display_snippet}...\")\n",
    "    else:\n",
    "        # Show content preview\n",
    "        content = result.get(\"content\", \"\")[:150]\n",
    "        print(f\"   Preview: {content}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36adf4",
   "metadata": {},
   "source": [
    "## 11. View Document Details\n",
    "\n",
    "Retrieve a specific document by its key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a specific document by key\n",
    "doc_id = \"doc-handbook\"\n",
    "document = search_client.get_document(key=doc_id)\n",
    "\n",
    "print(f\"üìÑ Document: {doc_id}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display as formatted JSON\n",
    "for key, value in document.items():\n",
    "    if key == \"content\":\n",
    "        # Truncate long content\n",
    "        print(f\"  {key}: {str(value)[:100]}...\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a9eb1",
   "metadata": {},
   "source": [
    "## 12. Cleanup (Optional)\n",
    "\n",
    "Delete the resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75529ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete all resources created in this notebook\n",
    "\n",
    "# Delete indexer\n",
    "# try:\n",
    "#     indexer_client.delete_indexer(INDEXER_NAME)\n",
    "#     print(f\"üóëÔ∏è Deleted indexer '{INDEXER_NAME}'\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Could not delete indexer: {e}\")\n",
    "\n",
    "# Delete skillset\n",
    "# try:\n",
    "#     indexer_client.delete_skillset(SKILLSET_NAME)\n",
    "#     print(f\"üóëÔ∏è Deleted skillset '{SKILLSET_NAME}'\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Could not delete skillset: {e}\")\n",
    "\n",
    "# Delete data source\n",
    "# try:\n",
    "#     indexer_client.delete_data_source_connection(DATA_SOURCE_NAME)\n",
    "#     print(f\"üóëÔ∏è Deleted data source '{DATA_SOURCE_NAME}'\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Could not delete data source: {e}\")\n",
    "\n",
    "# Delete index\n",
    "# try:\n",
    "#     index_client.delete_index(INDEX_NAME)\n",
    "#     print(f\"üóëÔ∏è Deleted index '{INDEX_NAME}'\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Could not delete index: {e}\")\n",
    "\n",
    "print(\"üí° Uncomment the code above to clean up resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848005b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "‚úÖ **Azure AI Search Python SDK** usage with the local simulator  \n",
    "‚úÖ **Index creation** with complex field types and analyzers  \n",
    "‚úÖ **Data source configuration** for local file system  \n",
    "‚úÖ **Custom Web API Skills** integration for document enrichment  \n",
    "‚úÖ **Indexer setup** with field mappings and output field mappings  \n",
    "‚úÖ **Document upload** using the push model  \n",
    "‚úÖ **Search queries**: simple, filtered, faceted, sorted, highlighted  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try the **pull model** with actual PDF documents\n",
    "- Add **vector search** with Azure OpenAI embeddings\n",
    "- Explore **hybrid search** (text + vector)\n",
    "- Build a custom skill for your specific use case\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Azure AI Search Documentation](https://learn.microsoft.com/azure/search/)\n",
    "- [Azure AI Search Python SDK](https://learn.microsoft.com/python/api/overview/azure/search-documents-readme)\n",
    "- [Custom Skills Sample](../CustomSkillSample/README.md)\n",
    "- [Simulator Limitations](../../docs/LIMITATIONS.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
